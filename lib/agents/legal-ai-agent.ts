import OpenAI from "openai"
import { ChatMemoryManager, ChatContext } from "@/lib/memory/chat-memory-manager"
import { UnifiedDeepResearchOrchestrator, UnifiedResearchConfig } from "@/lib/tongyi/unified-deep-research-orchestrator"
import { planLegalSearchStrategy } from "@/lib/tools/legal-search-planner"
import { runLegalSearchWorkflow } from "@/lib/tools/legal-search-orchestrator"

export interface AgentDecision {
  action: 'search' | 'respond' | 'clarify' | 'follow_up'
  confidence: number
  reasoning: string
  searchStrategy?: 'dynamic' | 'traditional' | 'hybrid'
  searchQueries?: string[]
  maxRounds?: number
}

export interface AgentResponse {
  content: string
  action: string
  metadata: {
    searchExecuted: boolean
    searchRounds?: number
    totalSearches?: number
    totalResults?: number
    finalQuality?: number
    modelDecisions?: number
    searchStrategy?: string
    sources?: Array<{
      title: string
      url: string
      type: string
      quality: number
    }>
  }
  memory: {
    messageId: string
    timestamp: Date
  }
}

export interface AgentOptions {
  client: OpenAI
  model: string
  chatId: string
  userId: string
  enableMemory: boolean
  enableAgenticSearch: boolean
  maxSearchRounds: number
  searchTimeoutMs: number
  apiKey: string
}

type ReasoningStatus =
  | "analyzing"
  | "planning"
  | "researching"
  | "validating"
  | "generating"
  | "clarifying"
  | "complete"

interface ReasoningDescriptor {
  status: ReasoningStatus
  description: string
}

/**
 * AI Agent con capacidades agenticas de b‚îú‚ïësqueda y memoria
 */
export class LegalAIAgent {
  private memoryManager: ChatMemoryManager
  private options: AgentOptions
  private unifiedOrchestrator: UnifiedDeepResearchOrchestrator

  constructor(options: AgentOptions) {
    this.options = options
    this.memoryManager = ChatMemoryManager.getInstance()
    this.unifiedOrchestrator = new UnifiedDeepResearchOrchestrator({
      apiKey: options.apiKey,
      modelName: options.model,
      legalDomain: 'colombia',
      qualityThreshold: 0.85,
      enableContinuousVerification: true,
      enableIterativeRefinement: true,
      maxRounds: 3, // Hard limit for stability
      maxSearchesPerRound: 5
    })
  }

  private attachReasoningSteps(steps: ReasoningDescriptor[], content: string): string {
    if (!steps.length) {
      return content
    }

    const reasoningBlock = steps
      .map(step => this.formatReasoningStep(step.status, step.description))
      .join("\n\n")

    return `${reasoningBlock}\n\n${content}`.trim()
  }

  private formatReasoningStep(status: ReasoningStatus, description: string): string {
    const sanitizedDescription = this.truncateForReasoning(description)
    return `[REASONING:${status}:${sanitizedDescription}]`
  }

  private truncateForReasoning(text: string, maxLength = 180): string {
    const normalized = text.replace(/\s+/g, " ").trim()
    if (normalized.length <= maxLength) {
      return normalized
    }
    return `${normalized.slice(0, maxLength - 3)}...`
  }

  private buildSearchReasoning(params: {
    userQuery: string
    strategy?: string
    totalSearches?: number
    totalResults?: number
    finalQuality?: number
    decisionReasoning?: string
    sourcesCount?: number
    rounds?: number
  }): ReasoningDescriptor[] {
    const {
      userQuery,
      strategy,
      totalSearches,
      totalResults,
      finalQuality,
      decisionReasoning,
      sourcesCount,
      rounds
    } = params

    const safeStrategy = strategy && strategy.trim() ? strategy : "investigacion"
    const safeSearches = typeof totalSearches === "number" && totalSearches > 0 ? totalSearches : 1
    const safeResults = typeof totalResults === "number" && totalResults >= 0 ? totalResults : 0
    const safeSources =
      typeof sourcesCount === "number" && sourcesCount > 0 ? sourcesCount : Math.min(safeResults, 5)

    return [
      {
        status: "analyzing",
        description: `Analizando la consulta del usuario: ${this.truncateForReasoning(userQuery, 120)}`
      },
      {
        status: "planning",
        description: decisionReasoning
          ? `Planificando estrategia ${safeStrategy} (${this.truncateForReasoning(decisionReasoning, 140)})`
          : `Definiendo estrategia ${safeStrategy}${rounds ? ` con hasta ${rounds} rondas` : ""}`
      },
      {
        status: "researching",
        description: `Ejecutando ${safeSearches} busquedas especializadas y analizando fuentes prioritarias`
      },
      {
        status: "validating",
        description: typeof finalQuality === "number"
          ? `Evaluando ${safeResults} resultados con calidad promedio ${finalQuality}/10`
          : `Depurando ${safeResults} resultados para garantizar relevancia y autoridad`
      },
      {
        status: "generating",
        description: "Sintetizando hallazgos y aplicando criterios legales colombianos"
      },
      {
        status: "complete",
        description: `Investigacion completada con ${safeSources} fuentes destacadas`
      }
    ]
  }

  private buildDirectAnswerReasoning(userQuery: string): ReasoningDescriptor[] {
    return [
      {
        status: "analyzing",
        description: `Analizando la consulta del usuario: ${this.truncateForReasoning(userQuery, 120)}`
      },
      {
        status: "generating",
        description: "Aplicando conocimiento juridico propio para elaborar la respuesta"
      },
      {
        status: "complete",
        description: "Respuesta legal lista para el usuario"
      }
    ]
  }

  private buildClarificationReasoning(
    userQuery: string,
    kind: "clarify" | "follow_up"
  ): ReasoningDescriptor[] {
    return [
      {
        status: "analyzing",
        description: `Analizando la consulta: ${this.truncateForReasoning(userQuery, 120)}`
      },
      {
        status: "clarifying",
        description:
          kind === "clarify"
            ? "Solicitando informacion adicional para aclarar la consulta"
            : "Formulando pregunta de seguimiento para profundizar en el caso"
      },
      {
        status: "complete",
        description: "Esperando respuesta del usuario para continuar"
      }
    ]
  }
  /**
   * Procesa una consulta del usuario con capacidades agenticas
   */
  async processQuery(
    userQuery: string,
    messageId: string
  ): Promise<AgentResponse> {
    console.log(`\n¬≠∆í√±√ª AI AGENT PROCESANDO CONSULTA`)
    console.log(`¬≠∆í√¥√ò Query: "${userQuery}"`)
    console.log(`¬≠∆í√Ü¬º Chat ID: ${this.options.chatId}`)
    console.log(`¬≠∆í√¶√± User ID: ${this.options.userId}`)
    console.log(`¬≠∆í¬∫√° Memoria: ${this.options.enableMemory ? 'ACTIVADA' : 'DESACTIVADA'}`)
    console.log(`¬≠∆í√∂√¨ B‚îú‚ïësqueda agentica: ${this.options.enableAgenticSearch ? 'ACTIVADA' : 'DESACTIVADA'}`)
    console.log(`${'='.repeat(80)}`)

    try {
      // 1. Cargar contexto de memoria si est‚îú√≠ habilitado
      let chatContext: ChatContext | null = null
      if (this.options.enableMemory) {
        chatContext = await this.memoryManager.getChatContext(
          this.options.chatId,
          this.options.userId
        )
        console.log(`¬≠∆í¬∫√° Contexto cargado: ${chatContext.conversationHistory.length} mensajes`)
      }

      // 2. Tomar decisi‚îú‚îÇn agentica sobre qu‚îú¬Æ hacer
      const decision = await this.makeAgenticDecision(userQuery, chatContext)
      console.log(`¬≠∆í√±√ª Decisi‚îú‚îÇn agentica: ${decision.action} (confianza: ${decision.confidence.toFixed(2)})`)
      console.log(`¬≠∆í√Ü¬° Razonamiento: ${decision.reasoning}`)

      // 3. Ejecutar acci‚îú‚îÇn basada en la decisi‚îú‚îÇn
      let response: AgentResponse

      switch (decision.action) {
        case 'search':
          response = await this.executeSearchAction(userQuery, decision, chatContext)
          break
        case 'respond':
          response = await this.executeRespondAction(userQuery, chatContext)
          break
        case 'clarify':
          response = await this.executeClarifyAction(userQuery, chatContext)
          break
        case 'follow_up':
          response = await this.executeFollowUpAction(userQuery, chatContext)
          break
        default:
          response = await this.executeRespondAction(userQuery, chatContext)
      }

      // 4. Guardar en memoria si est‚îú√≠ habilitado
      if (this.options.enableMemory) {
        await this.memoryManager.saveMessage(
          this.options.chatId,
          this.options.userId,
          messageId,
          response.content,
          'assistant',
          response.metadata
        )
      }

      console.log(`√î¬£√† Respuesta generada: ${response.content.length} caracteres`)
      return response

    } catch (error) {
      console.error(`√î√ò√Æ Error en AI Agent:`, error)
      
      // Respuesta de error con fallback
      const errorResponse: AgentResponse = {
        content: `Disculpa, hubo un error t‚îú¬Æcnico al procesar tu consulta. Por favor, intenta nuevamente.`,
        action: 'error',
        metadata: {
          searchExecuted: false
        },
        memory: {
          messageId,
          timestamp: new Date()
        }
      }

      if (this.options.enableMemory) {
        await this.memoryManager.saveMessage(
          this.options.chatId,
          this.options.userId,
          messageId,
          errorResponse.content,
          'assistant',
          errorResponse.metadata
        )
      }

      return errorResponse
    }
  }

  /**
   * Toma una decisi‚îú‚îÇn agentica sobre qu‚îú¬Æ acci‚îú‚îÇn realizar
   */
  private async makeAgenticDecision(
    userQuery: string,
    chatContext: ChatContext | null
  ): Promise<AgentDecision> {
    try {
      const contextInfo = chatContext ? `
HISTORIAL DE CONVERSACI‚îú√¥N:
${chatContext.currentContext}

B‚îú√úSQUEDAS ANTERIORES:
${chatContext.searchHistory.slice(-3).map(s => `- "${s.query}" (${s.results} resultados, calidad: ${s.quality}/10)`).join('\n')}

PREFERENCIAS DEL USUARIO:
- Estrategia: ${chatContext.userPreferences.preferredSearchStrategy}
- M‚îú√≠ximo de rondas: ${chatContext.userPreferences.maxSearchRounds}
- Decisi‚îú‚îÇn del modelo: ${chatContext.userPreferences.enableModelDecision ? 'Activada' : 'Desactivada'}
` : 'Sin historial previo'

      const decisionPrompt = `Eres un agente de IA legal experto que debe decidir qu‚îú¬Æ acci‚îú‚îÇn tomar para responder una consulta del usuario.

CONSULTA ACTUAL: "${userQuery}"

${contextInfo}

CAPACIDADES DISPONIBLES:
1. **search**: Realizar b‚îú‚ïësqueda web din‚îú√≠mica con m‚îú‚ïëltiples rondas
2. **respond**: Responder directamente con conocimiento existente
3. **clarify**: Pedir aclaraciones al usuario
4. **follow_up**: Hacer preguntas de seguimiento

CRITERIOS DE DECISI‚îú√¥N:
- Si la consulta requiere informaci‚îú‚îÇn actualizada o espec‚îú¬°fica √î√•√Ü **search**
- Si la consulta es general y tienes conocimiento suficiente √î√•√Ü **respond**
- Si la consulta es ambigua o incompleta √î√•√Ü **clarify**
- Si necesitas m‚îú√≠s informaci‚îú‚îÇn para completar la respuesta √î√•√Ü **follow_up**

ESTRATEGIAS DE B‚îú√úSQUEDA:
- **dynamic**: Sistema de b‚îú‚ïësqueda din‚îú√≠mica (hasta 10 rondas, modelo decide)
- **traditional**: Sistema tradicional (hasta 5 rondas, criterios fijos)
- **hybrid**: Combinaci‚îú‚îÇn de ambos sistemas

Responde en formato JSON:
{
  "action": "search|respond|clarify|follow_up",
  "confidence": 0.0-1.0,
  "reasoning": "explicaci‚îú‚îÇn detallada de la decisi‚îú‚îÇn",
  "searchStrategy": "dynamic|traditional|hybrid",
  "searchQueries": ["consulta espec‚îú¬°fica 1", "consulta espec‚îú¬°fica 2"],
  "maxRounds": 5-10
}`

      const response = await this.options.client.chat.completions.create({
        model: this.options.model,
        messages: [
          { role: "system", content: decisionPrompt },
          { role: "user", content: `Analiza la consulta y decide qu‚îú¬Æ acci‚îú‚îÇn tomar: "${userQuery}"` }
        ],
        temperature: 0.1,
        max_tokens: 800,
        stream: false
      })

      const content = response.choices?.[0]?.message?.content || '{}'
      const decision = this.parseAgentDecision(content)

      // Validar decisi‚îú‚îÇn
      if (!decision.action || !['search', 'respond', 'clarify', 'follow_up'].includes(decision.action)) {
        decision.action = 'search' // Fallback a b‚îú‚ïësqueda
        decision.confidence = 0.5
        decision.reasoning = 'Decisi‚îú‚îÇn inv‚îú√≠lida, usando fallback a b‚îú‚ïësqueda'
      }

      return decision

    } catch (error) {
      console.error('Error en decisi‚îú‚îÇn agentica:', error)
      
      // Fallback a b‚îú‚ïësqueda din‚îú√≠mica
      return {
        action: 'search',
        confidence: 0.5,
        reasoning: 'Error en decisi‚îú‚îÇn agentica, usando fallback a b‚îú‚ïësqueda',
        searchStrategy: 'dynamic',
        searchQueries: [userQuery],
        maxRounds: this.options.maxSearchRounds
      }
    }
  }

  /**
   * Ejecuta acci‚îú‚îÇn de b‚îú‚ïësqueda
   */
  private async executeSearchAction(
    userQuery: string,
    decision: AgentDecision,
    chatContext: ChatContext | null
  ): Promise<AgentResponse> {
    console.log(`üîç Ejecutando b√∫squeda agentica con estrategia: ${decision.searchStrategy}`)

    try {
      let searchResult: any
      let metadata: AgentResponse['metadata']

      // FORCE iter_research mode for stability with Tongyi/Kimi
      // This replaces the unstable dynamic loop
      const effectiveMode = 'iter_research' 
      console.log(`üîí Forzando modo seguro: ${effectiveMode} (Max 3 rondas)`)

      const orchestratorResult = await this.unifiedOrchestrator.orchestrate(
        userQuery,
        this.options.chatId,
        this.options.userId,
        {
          mode: effectiveMode,
          maxRounds: 3, // Strict limit
          maxSearchesPerRound: 5
        }
      )

      metadata = {
        searchExecuted: true,
        searchRounds: orchestratorResult.metadata.totalRounds,
        totalSearches: orchestratorResult.metadata.totalSearches,
        totalResults: orchestratorResult.metadata.totalSources,
        finalQuality: orchestratorResult.analysis.qualityScore * 10, // Scale to 0-10
        modelDecisions: 0, // Orchestrator handles this internally
        searchStrategy: effectiveMode,
        sources: orchestratorResult.sources.map((source: any) => ({
          title: source.title,
          url: source.url,
          type: source.type,
          quality: source.quality
        }))
      }

      // Registrar b√∫squeda en memoria
      if (this.options.enableMemory && chatContext) {
        await this.memoryManager.recordSearch(
          this.options.chatId,
          this.options.userId,
          userQuery,
          orchestratorResult.metadata.totalSources,
          orchestratorResult.analysis.qualityScore * 10
        )
      }

      return {
        content: orchestratorResult.finalAnswer,
        action: 'search',
        metadata,
        memory: {
          messageId: `${this.options.chatId}-${Date.now()}`,
          timestamp: new Date()
        }
      }

    } catch (error) {
      console.error('Error en b√∫squeda agentica:', error)
      
      // Fallback a respuesta sin b√∫squeda
      const response = await this.generateResponseWithContext(
        userQuery,
        'Error en b√∫squeda, respondiendo con conocimiento general',
        chatContext
      )

      return {
        content: response,
        action: 'search',
        metadata: {
          searchExecuted: false
        },
        memory: {
          messageId: `${this.options.chatId}-${Date.now()}`,
          timestamp: new Date()
        }
      }
    }
  }

  /**
   * Ejecuta acci‚îú‚îÇn de respuesta directa
   */
  private async executeRespondAction(
    userQuery: string,
    chatContext: ChatContext | null
  ): Promise<AgentResponse> {
    console.log(`¬≠∆í√Ü¬º Respondiendo directamente sin b‚îú‚ïësqueda`)

    const response = await this.generateResponseWithContext(
      userQuery,
      'Responde usando tu conocimiento legal colombiano sin realizar b‚îú‚ïësquedas web',
      chatContext
    )

    return {
      content: response,
      action: 'respond',
      metadata: {
        searchExecuted: false
      },
      memory: {
        messageId: `${this.options.chatId}-${Date.now()}`,
        timestamp: new Date()
      }
    }
  }

  /**
   * Ejecuta acci‚îú‚îÇn de aclaraci‚îú‚îÇn
   */
  private async executeClarifyAction(
    userQuery: string,
    chatContext: ChatContext | null
  ): Promise<AgentResponse> {
    console.log(`√î√ò√¥ Solicitando aclaraci‚îú‚îÇn`)

    const clarificationPrompt = `La consulta "${userQuery}" es ambigua o incompleta. Genera una pregunta de aclaraci‚îú‚îÇn espec‚îú¬°fica para obtener m‚îú√≠s informaci‚îú‚îÇn del usuario.`

    const response = await this.options.client.chat.completions.create({
      model: this.options.model,
      messages: [
        { role: "system", content: "Eres un asistente legal que necesita aclarar consultas ambiguas." },
        { role: "user", content: clarificationPrompt }
      ],
      temperature: 0.3,
      max_tokens: 300,
      stream: false
    })

    const content = response.choices?.[0]?.message?.content || "‚î¨‚îêPodr‚îú¬°as ser m‚îú√≠s espec‚îú¬°fico en tu consulta?"

    return {
      content,
      action: 'clarify',
      metadata: {
        searchExecuted: false
      },
      memory: {
        messageId: `${this.options.chatId}-${Date.now()}`,
        timestamp: new Date()
      }
    }
  }

  /**
   * Ejecuta acci‚îú‚îÇn de seguimiento
   */
  private async executeFollowUpAction(
    userQuery: string,
    chatContext: ChatContext | null
  ): Promise<AgentResponse> {
    console.log(`¬≠∆í√∂√§ Generando pregunta de seguimiento`)

    const followUpPrompt = `Bas‚îú√≠ndote en la consulta "${userQuery}" y el contexto de conversaci‚îú‚îÇn, genera una pregunta de seguimiento ‚îú‚ïëtil para obtener m‚îú√≠s informaci‚îú‚îÇn espec‚îú¬°fica.`

    const response = await this.options.client.chat.completions.create({
      model: this.options.model,
      messages: [
        { role: "system", content: "Eres un asistente legal que hace preguntas de seguimiento inteligentes." },
        { role: "user", content: followUpPrompt }
      ],
      temperature: 0.3,
      max_tokens: 300,
      stream: false
    })

    const content = response.choices?.[0]?.message?.content || "‚î¨‚îêHay alg‚îú‚ïën aspecto espec‚îú¬°fico que te gustar‚îú¬°a que profundice?"

    return {
      content,
      action: 'follow_up',
      metadata: {
        searchExecuted: false
      },
      memory: {
        messageId: `${this.options.chatId}-${Date.now()}`,
        timestamp: new Date()
      }
    }
  }

  /**
   * Genera respuesta usando contexto enriquecido
   */
  private async generateResponseWithContext(
    userQuery: string,
    searchContext: string,
    chatContext: ChatContext | null
  ): Promise<string> {
    const systemPrompt = `Eres un asistente legal experto en derecho colombiano. Utiliza EXCLUSIVAMENTE la informaci‚îú‚îÇn proporcionada para responder la consulta del usuario.

${searchContext}

${chatContext ? `CONTEXTO DE CONVERSACI‚îú√¥N:
${chatContext.currentContext}` : ''}

INSTRUCCIONES:
1. Responde de manera completa y precisa
2. Usa terminolog‚îú¬°a jur‚îú¬°dica apropiada
3. Incluye referencias a art‚îú¬°culos y leyes cuando sea relevante
4. Proporciona informaci‚îú‚îÇn pr‚îú√≠ctica y aplicable
5. Si hay informaci‚îú‚îÇn insuficiente, ind‚îú¬°calo claramente
6. Responde en espa‚îú‚ñíol colombiano`

    const response = await this.options.client.chat.completions.create({
      model: this.options.model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: `Consulta: "${userQuery}"` }
      ],
      temperature: 0.2,
      max_tokens: 2000,
      stream: false
    })

    return response.choices?.[0]?.message?.content || "No pude generar una respuesta adecuada."
  }

  /**
   * Parsea la decisi‚îú‚îÇn del agente desde JSON
   */
  private parseAgentDecision(content: string): AgentDecision {
    try {
      const jsonText = this.extractJson(content)
      const parsed = JSON.parse(jsonText)
      
      return {
        action: parsed.action || 'search',
        confidence: parsed.confidence || 0.5,
        reasoning: parsed.reasoning || 'Sin razonamiento proporcionado',
        searchStrategy: parsed.searchStrategy || 'dynamic',
        searchQueries: parsed.searchQueries || [],
        maxRounds: parsed.maxRounds || this.options.maxSearchRounds
      }
    } catch (error) {
      console.error('Error parseando decisi‚îú‚îÇn del agente:', error)
      return {
        action: 'search',
        confidence: 0.5,
        reasoning: 'Error parseando decisi‚îú‚îÇn, usando fallback',
        searchStrategy: 'dynamic',
        searchQueries: [],
        maxRounds: this.options.maxSearchRounds
      }
    }
  }

  /**
   * Extrae JSON del contenido
   */
  private extractJson(content: string): string {
    const start = content.indexOf('{')
    const end = content.lastIndexOf('}')
    if (start === -1 || end === -1 || end <= start) {
      throw new Error("JSON no encontrado en el contenido")
    }
    return content.slice(start, end + 1)
  }

  /**
   * Obtiene estad‚îú¬°sticas del agente
   */
  async getAgentStats(): Promise<{
    memoryEnabled: boolean
    agenticSearchEnabled: boolean
    maxSearchRounds: number
    chatStats: {
      totalMessages: number
      totalSearches: number
      averageQuality: number
      lastActivity: Date | null
    }
  }> {
    const chatStats = await this.memoryManager.getMemoryStats(
      this.options.chatId,
      this.options.userId
    )

    return {
      memoryEnabled: this.options.enableMemory,
      agenticSearchEnabled: this.options.enableAgenticSearch,
      maxSearchRounds: this.options.maxSearchRounds,
      chatStats
    }
  }
}










